i want to build an agentic ai redaction app, "cursor for document redaction"
it should redact pdf and docx documents for pii and/or foi request release criteria
frontend nextjs, backend fastapi python, should be deployable a) ideally via vercel b) via docker container
prior work:
- ../redaction-ui: react component for manually redacting pdfs in the browser; this is ours and you can also just go there and make edits in there
- ../redaction-rules: collection of reasons for redactions for foi requested documents for multiple legislations. usually one of the rules is essentially pii redaction. that's also the most actionable one, since the other rules require a lot of context from the user but pii can be automated to some extent
- /Users/david/Repositories/redaction-app/backend/app/api.py: previous api for redaction rule generation via ai; mostly just for inspiration, but what we need to exactly copy from there is how the cloud vs local models are loaded (though we will use gpt-5.2 which is more recent)
- /Users/david/UN/un80-sg-reports-survey/src/components/chat, /Users/david/UN/un80-sg-reports-survey/src/app/api/chat/route.ts: a mostly unrelated project, but it does have this really nice shadcn chat component and tool use logic; copy that component and adjust it for our purposes
research all these a bit to better understand before we start
what we want to build is "cursor for document redaction", ie agentic document redaction (via tool use in a loop in a chat)
basic idea: user has a pdf view in the browser and can make manual redactions, but the main feature is a chat sidebar on the right side where they can chat with the ai which understands the document, asks back questions, and can then rapidly / in bulk suggest redactions
bulk upload of pdfs should be possible, in which case the ai has context on all documents at once and can suggest redactions across documents
docx should also be supported, but simply by converting to pdf and then editing the pdf -- lets discuss options here
for pdf processing use pymupdf aka mupdf js, as in the prior projects. pymupdf is somewhat more convenient than mupdfjs but since we already use mupdfjs in the frontend it might give us a simpler code structure which is useful
concise minimal fp-inspired code is key to a complex project like this; also make sure that all errors are thrown and/or displayed to the user and there's no silent error failing
there are certain settings to be considered:
- what ai model to use:
  - ideally a cloud model like gpt-5.2 or oss cloud alternatives like llama or deepseek or glm (research their latest versions). this is an app designed for german ministries, especially bmz, and they are paranoid about cloud processing esp with us providers. we need to make them comfortable: azure has x certifications for processing personal data, there is zero data retention so that even with the cloud act noone could access the data, and besides that the cloud act has never been applied to government customers in the eu according to reporting by azure/aws/googlecloud. we also need to provide local alternatives though:
  - local llm: /Users/david/Repositories/redaction-app/backend/app/api.py defines snippets that can load a local llm on the bmz ministry gpu server
  - nlp models: spacy / stanza / iiiorg/piiranha-v1-detect-personal-information -- for starters lets just do spacy de_core_news_lg (though its not great); also include buttons etc for the other ones but dont implement them yet
  - local in-browser nlp models: see ../securedact for such an approach. this is tricky to configure with react but does work. for starters include buttons etc for this option but do not implement it
- what redaction mode to use: just pii, or foi. in case of foi, lets have the "reason selector" in the ui for selecting applicable rules, and also include this as part of the ai processing. in case of pii it's simpler, just redact by adding the black boxes without any reasons displayed or needing to be selected
- what sorts of persons and organization to redact and not to redact: eg users may want to redact pii of private persons, but not of persons acting in an official function; or they may want to only redact pii of lower officials but not of higher officials such as abteilungsleiter and minister
- what sorts of information to redact for the persons/orgs: names / (personal vs functional) email addresses / phone numbers / money sums (perhaps only of a certain kind), etc, etc
we want to set all this settings logic up as part of the ai conversation. that allows users to also ask questions about the options, and we can explain to them eg that cloud ai is usually ok except if its really very sensitive. so we won't have these questions hardcoded, but rather put them into the prompt of the ai chat agent and give the agent a tool (if you dont know tool calling, research it, and check the example from un eosg) to ask a question to the user with pre-defined answer options (which the ui will then display and give back to the chat when the user clicks on them) as well as option to do freeform answer and continue chatting. pdf content should only be made available to the ai in case that the user agrees to use cloud/local llms (and depending on whether they select cloud or local it should switch to the respective ai model -- its fine to start with cloud llm for the chat since we wont have sensitive data in the chat at the start). pdf content should only be made available, once the user selects one of these options, and the ai should not be able make that decision autonomously, eg if the user says in chat they want to use the cloud model and the ai uses a tool for reading the pdf into the clpud model (itself) then this should not be able to happen automatically but there must be a barrier in the code to trigger a user interaction outside of the chat to confirm this.
when the user selects to use one of the non-llms, e.g. spacy, then the llm will make a final tool call to start spacy processing and display that in the leftside toolbar and in the document and explain that, but it will not obtain access to itself read the document or the spacy-suggested redactions. it will remain available for further generic questions. eg maybe the user has generic questions on foi laws that are not sensitive and still useful to chat about while working with the more confidential model on the other side.
on the left we want to have a sidebar with 3 functions (tabs within that sidebar):
- miniature view of pdf thumbnails, as known from pdf viewers (redactions do not need to show up within the thumbnails but maybe a count indicator circle in the corner of the thumbnail about how many redactions are on a given page)
- list of all redactions in chronological order of the document
- list of all redactions grouped by a) level 1: the persons and orgs that they belong to (e.g "max mustermann", "friedrich merz", "bmz") and b) level 2: the different groups of persons/orgs that occur within the documents (e.g. "citizens", "civil servants", "persons in bmz", "persons in giz", etc) -- this grouping must also be part of the schema that the ai analysis returns
the ai should not just blind-stumble and make redaction suggestions by guessing, but should before it does that converse with the user until it has a good understanding of what sort of things the user wants redacted and what not. then it should create the suggestions. there should be a level of confidence of "high" and "low", where "low" means that the ai is uncertain whether or not this should be redacted. there should be very few "low" suggestions, since the ai should try to remove as much ambiguity as possible by chatting. but for _individual_ cases of text snippets that are still ambiguous of whether they should be redacted or not, its better to just suggest them with "low" so the user sees them in context in the document.
ai suggestions have default status "suggested" and options in the ui to a) [checkmark] accept or b) [x] ignore. in case they are accepted they will have a checkmark displayed, in case they are ignored they will simply be removed. all user interactions should (if the user is in llm mode) be reported back to the llm so that it knows whats going on. (it should not trigger a direct response by the llm but should be added to the llm context in case the user wants to continue chatting later, and then the llm should be up to date on what the user did in the meantime)
chat sessions should be persisted in localstorage.
as you see, this is an immensely innovative and complex project.
lets thoroghly think through it together before we implement it.
also push back on my ideas where they are unclear or dont make sense.
ask a lot of questions to me to understand better.
let's get this going!